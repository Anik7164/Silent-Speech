<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Silent Speech Keyboard - Face Tracking</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@0.0.1/dist/face-landmarks-detection.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
            color: #333;
        }
        h1 {
            color: #2c3e50;
            text-align: center;
        }
        #camera-container {
            position: relative;
            margin: 20px auto;
            width: 640px;
            height: 480px;
            border: 3px solid #3498db;
            border-radius: 8px;
            overflow: hidden;
        }
        #webcam {
            width: 100%;
            height: 100%;
            background: #ddd;
        }
        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        #output-text {
            min-height: 100px;
            padding: 15px;
            margin: 20px 0;
            border: 1px solid #ccc;
            border-radius: 5px;
            background: white;
            font-size: 24px;
        }
        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
        }
        button {
            padding: 10px 20px;
            background: #3498db;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
        }
        button:hover {
            background: #2980b9;
        }
        .status {
            margin-top: 20px;
            padding: 10px;
            border-radius: 5px;
            text-align: center;
        }
        .loading {
            background: #f39c12;
            color: white;
        }
        .success {
            background: #2ecc71;
            color: white;
        }
        .error {
            background: #e74c3c;
            color: white;
        }
        .landmark-info {
            margin-top: 20px;
            padding: 15px;
            background: #fff;
            border-radius: 5px;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <h1>Silent Speech Keyboard</h1>
    <p>Watch the AI detect your face and lips in real-time!</p>
    
    <div id="camera-container">
        <video id="webcam" autoplay muted playsinline></video>
        <canvas id="canvas"></canvas>
    </div>
    
    <div id="output-text">Lip movements will appear here...</div>
    
    <div class="controls">
        <button id="startBtn">Start Detection</button>
        <button id="clearBtn">Clear Text</button>
    </div>
    
    <div id="status" class="status">Waiting to initialize...</div>
    
    <div class="landmark-info">
        <h3>Lip Landmark Indices (MediaPipe Face Mesh)</h3>
        <p>Inner Lips: 61-80 | Outer Lips: 0-11, 38-49</p>
        <p id="landmarkData">No data yet...</p>
    </div>

    <script>
        // DOM Elements
        const webcam = document.getElementById('webcam');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const outputText = document.getElementById('output-text');
        const startBtn = document.getElementById('startBtn');
        const clearBtn = document.getElementById('clearBtn');
        const statusDiv = document.getElementById('status');
        const landmarkData = document.getElementById('landmarkData');
        
        // State
        let model;
        let isRunning = false;
        let animationId;

        // Initialize Camera
        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { width: 640, height: 480 },
                    audio: false 
                });
                webcam.srcObject = stream;
                statusDiv.textContent = "Camera ready!";
                statusDiv.className = "status success";
                return new Promise((resolve) => {
                    webcam.onloadedmetadata = () => {
                        canvas.width = webcam.videoWidth;
                        canvas.height = webcam.videoHeight;
                        resolve(true);
                    };
                });
            } catch (err) {
                statusDiv.textContent = `Camera error: ${err.message}`;
                statusDiv.className = "status error";
                return false;
            }
        }

        // Load Face Landmarks Model
        async function loadModel() {
            statusDiv.textContent = "Loading AI model...";
            statusDiv.className = "status loading";
            
            try {
                model = await faceLandmarksDetection.load(
                    faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,
                    { maxFaces: 1 }
                );
                statusDiv.textContent = "Model loaded!";
                statusDiv.className = "status success";
                return true;
            } catch (err) {
                statusDiv.textContent = `Model error: ${err.message}`;
                statusDiv.className = "status error";
                return false;
            }
        }

        // Draw Face and Lip Landmarks
        function drawLandmarks(predictions) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            if (predictions.length > 0) {
                const keypoints = predictions[0].scaledMesh;
                
                // Draw all face landmarks (468 points)
                ctx.fillStyle = 'white';
                for (let i = 0; i < keypoints.length; i++) {
                    const x = keypoints[i][0];
                    const y = keypoints[i][1];
                    
                    // Highlight lip landmarks (61-80)
                    if (i >= 61 && i <= 80) {
                        ctx.fillStyle = 'red';
                        ctx.fillRect(x, y, 3, 3);
                    } else {
                        ctx.fillStyle = 'rgba(255, 255, 255, 0.5)';
                        ctx.fillRect(x, y, 2, 2);
                    }
                }
                
                // Display lip landmark coordinates
                const lips = keypoints.slice(61, 80);
                landmarkData.textContent = `Lip Center: X=${lips[0][0].toFixed(1)}, Y=${lips[0][1].toFixed(1)}`;
                
                // Detect if mouth is open
                const upperLip = keypoints[13][1];
                const lowerLip = keypoints[14][1];
                const mouthOpen = lowerLip - upperLip > 15;
                
                if (mouthOpen) {
                    outputText.textContent += "A";
                    ctx.fillStyle = 'lime';
                    ctx.font = '20px Arial';
                    ctx.fillText('MOUTH OPEN', 20, 50);
                }
            }
        }

        // Main Detection Loop
        async function detectFaces() {
            if (!model) return;
            
            const predictions = await model.estimateFaces({
                input: webcam,
                returnTensors: false,
                flipHorizontal: false,
                predictIrises: false
            });
            
            drawLandmarks(predictions);
            animationId = requestAnimationFrame(detectFaces);
        }

        // Start/Stop Detection
        startBtn.addEventListener('click', async () => {
            if (!isRunning) {
                const camReady = await setupCamera();
                const modelReady = await loadModel();
                
                if (camReady && modelReady) {
                    isRunning = true;
                    startBtn.textContent = "Stop Detection";
                    detectFaces();
                }
            } else {
                isRunning = false;
                startBtn.textContent = "Start Detection";
                cancelAnimationFrame(animationId);
                ctx.clearRect(0, 0, canvas.width, canvas.height);
            }
        });

        // Clear Text
        clearBtn.addEventListener('click', () => {
            outputText.textContent = "";
        });
    </script>
</body>
</html>